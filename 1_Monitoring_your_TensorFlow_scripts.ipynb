{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor and Analyze Training Jobs Using Metrics\n",
    "An Amazon SageMaker training job is an iterative process that teaches a model to make predictions by presenting examples from a training dataset.  \n",
    "Typically, a training algorithm computes several metrics, such as training error and prediction accuracy. These metrics help diagnose whether the model is learning well and will generalize well for making predictions on unseen data.  \n",
    "\n",
    "The training algorithm writes the values of these metrics to logs, which Amazon SageMaker monitors and sends to Amazon CloudWatch in real time.\n",
    "\n",
    "If you want Amazon SageMaker to parse logs from a custom algorithm and send metrics that the algorithm emits to CloudWatch, you have to specify the metrics that you want Amazon SageMaker to send to CloudWatch when you configure the training job.  \n",
    "You specify the name of the metrics that you want to send and the regular expressions that Amazon SageMaker uses to parse the logs that your algorithm emits to find those metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Metrics (Amazon SageMaker Python SDK)\n",
    "Define the metrics that you want to send to CloudWatch by specifying a list of metric names and regular expressions as the metric_definitions argument when you initialize an Estimator object. For example, if you want to monitor both the train:error and validation:error metrics in CloudWatch, your Estimator initialization would look like the following:\n",
    "```python \n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       metric_definitions=[\n",
    "                               {'Name': 'train:error', 'Regex': 'Train_error=(.*?);'},\n",
    "                               {'Name': 'validation:error', 'Regex': 'Valid_error=(.*?);'}\n",
    "                        ],\n",
    "                       hyperparameters={'epochs' : 20},\n",
    "                       train_instance_count=1, train_instance_type='ml.p3.2xlarge')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the cifar10 training\n",
    "Find your previous (cifar10_keras_sm) training job in the SageMaker console.\n",
    "Open the job details and look at the job cloudwatch logs.  \n",
    "Configure the metrics regex that fits the logs. use regex tools to check your expressions, use () to catch each matric\n",
    "In this example, the solution (One option for a solution) is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+) - acc: [0-9\\\\.]+'},\n",
    "    {'Name': 'train:accuracy', 'Regex': 'loss: [0-9\\\\.]+ - acc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': 'val_loss: [0-9\\\\.]+ - val_acc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+) - val_acc: [0-9\\\\.]+'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with the notebook and run the same job as before (Same estimator configuration).  this time, add the ```metric_definitions=metric_definitions``` argument.  \n",
    "Run the job for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SageMaker experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "import time\n",
    "cifar10_experiment = Experiment.load(\n",
    "    experiment_name=\"TensorFlow-cifar10-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new trial\n",
    "trial_name = f\"cifar10-training-job-{int(time.time())}\"\n",
    "trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=cifar10_experiment.experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure the dataset location variable\n",
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = ... # Make sure you use the metric_definitions=metric_definitions argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect the trial configured above to the job. add the experiment config to the fit function.\n",
    "```python\n",
    "experiment_config={\n",
    "                  \"ExperimentName\": cifar10_experiment.experiment_name, \n",
    "                  \"TrialName\": trial.trial_name,\n",
    "                  \"TrialComponentDisplayName\": \"Training\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train' :  'train_data_location',\n",
    "               'validation' :  'validation_data_location',\n",
    "               'eval' :  'eval_data_location'},\n",
    "             experiment_config=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "SageMaker used the regular expression configured above, to send the job metrics to CloudWatch metrics.\n",
    "You can now view the job metrics directly from the SageMaker console.  \n",
    "\n",
    "login to the [SageMaker console](https://console.aws.amazon.com/sagemaker/home) choose the latest training job, scroll down to the monitor section.  \n",
    "Using CloudWatch metrics, you can change the period and configure the statistics\n",
    "\n",
    "Find the metrics using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'https://console.aws.amazon.com/cloudwatch/home?region='+sagemaker_session.boto_region_name+'#metricsV2:query=%7B/aws/sagemaker/TrainingJobs,TrainingJobName%7D%20'+estimator.latest_training_job.job_name\n",
    "display(Markdown('CloudWatch metrics: [link]('+link+')'))\n",
    "display(Markdown('After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor with TensorBoard\n",
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    "* Tracking and visualizing metrics such as loss and accuracy\n",
    "* Visualizing the model graph (ops and layers)\n",
    "* Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "* Projecting embeddings to a lower dimensional space\n",
    "* Displaying images, text, and audio data\n",
    "* And much more\n",
    "\n",
    "In the next section we'll update the script to save TensorBoard logs.  \n",
    "We'll be able to use TensorBoard for monitoring our jobs in real time.  \n",
    "\n",
    "Update your cifar10-keras-sm.py script to send logs to TensorBoard.  \n",
    "Add the `from keras.callbacks import TensorBoard` import.\n",
    "\n",
    "Keras will send TensorBoard logs in each batch. sending the logs to S3 will slow down the training job, change the TensorBoard callback to send the logs only at the end of an epoch.\n",
    "\n",
    "Add the TensorBoard callback to your script (add this line after the ModelCheckpoint callback)\n",
    "```python\n",
    "tb_callback = TensorBoard(log_dir=args.model_dir,update_freq='epoch')\n",
    "```\n",
    "\n",
    "Add tb_callback to the model.fit callbacks list.\n",
    "```python\n",
    "callbacks=[checkpoint, tb_callback]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a training job with TensorBoard support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new trial\n",
    "trial_name = f\"cifar10-training-job-{int(time.time())}\"\n",
    "trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=cifar10_experiment.experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train' :  'train_data_location',\n",
    "               'validation' :  'validation_data_location',\n",
    "               'eval' :  'eval_data_location'},\n",
    "              experiment_config=,\n",
    "              wait=False) # Use wait=False to run async jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Tensorboard on your local machine\n",
    "Install [TensorBoard](https://github.com/tensorflow/tensorboard) locally (On you computer) using `pip install tensorboard`.  \n",
    "To access an S3 log directory, configure the TensorBoard default region.  \n",
    "You can do this by configuring an environment variable named AWS_REGION, and setting the value of the environment variable to the AWS region your training job runs in.  \n",
    "For example, `AWS_REGION='us-east-1' tensorboard --logdir model_dir`  \n",
    "\n",
    "**You can get your TensorBoard command from the next cell.**\n",
    "\n",
    "You'll need an AccessKey + SecretKey with access to model_dir for this Event, get those from https://dashboard.eventengine.run/dashboard.  \n",
    "\n",
    "AWS Console -> copy the Credentials / CLI Snippets and run in your Terminal / CMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'AWS_REGION=\\''+sagemaker_session.boto_region_name+'\\' tensorboard --logdir ' + estimator.model_dir\n",
    "display(Markdown('TensorBoard command: '+link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access TensorBoard locally at http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=cifar10_experiment.experiment_name,\n",
    "    search_expression=search_expression\n",
    ")\n",
    "\n",
    "table = trial_component_analytics.dataframe(force_refresh=True)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good job!**   \n",
    "You can now monitor your job using both CloudWatch metrics and TensorBoard.  \n",
    "Before continuing to the next notebook, take a look at the [TensorBoard callback configuration](https://keras.io/callbacks/#tensorboard) for other TensorBoard configurations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}